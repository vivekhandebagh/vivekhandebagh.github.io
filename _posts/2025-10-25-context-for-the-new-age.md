---
layout: post
title: "Context for the New Age"
author: "Vivek S. Handebagh"
date: 2025-10-25
math: false
---

<img src="/assets/images/golden_gate.jpg" alt="golden gate" width="60%" />

Do you see the new age coming? Or do you see it already here?

The evolution of large scale intelligence will pave the way for a world where cognitive labor is rendered economically obsolete. I do not necessarily assume the stance that this new world is inherently dangerous, unproductive, or undesirable. The transition into a prosperous post-labor economy where people no longer need to toil for their wages is not unrealistic. Positive-sum systems can be setup in place such that abundance is generated for all, even if not uniformly distributed. 

However, the fear is that in the absence of higher principles, abundance by itself becomes corrosive. When technology advances faster than wisdom, civilizations begin to enter a state where intelligence expands rapidly, but the cloud of an overwhelming lack of meaning casts us into a profound moral confusion. Talk to any generation millenial or later, you will not fail to find the nihilistic void on the other side of their skin. It's like their words, posts, and spending habits have attached to them a drooping laundry bag of dread.  

For now, language models and autonomous networks are still in their primitive state of being tools. But it is foolish to turn a blind eye to their nearing roles as the new centers of agency. They will be the new bearers of will. The question, then, is no longer whether intelligence will govern the world, but what kind of intelligence will govern it. And thus, the question of alignment: how an artificial intelligence system can be made to act in accordance with a desired set of values, has become the defining philosophical and technical problem of our time. 

What you need to understand is that every model inherits a latent metaphysics. Larger generalizations and worldviews are hidden under the statistics of the syntactical patterns of training data. When millions of people query and interact with these systems daily, they are tuning their cognition against the model’s implicit priors about reality. The model’s biases, even if small, ripple through human behavior and culture. You see this with the way people talk to the sycophantic base models about their relationships and personal problems. The immediate sense of validation and eternal sense of patience exponentiate confirmation bias and drive wedges between human-to-human compromise and connection.

Any mainstream discourse that does exist, tends to treat the problem as one of control, of trying to control these systems to align with humans. But this presumes that human values are coherent, well-defined, and ethically sufficient. And are we so sure about this? If you look at human history, you'll see that she is a reflection of our own faces-- just without lip balm or pimple patches. Our desires are inconsistent, our incentives short-term, and our moral intuitions easily warped by scale, power, and novelty. The systems we build will not merely reflect, but amplify these distorted incentives and limitations.

An intelligence that optimizes purely for efficiency learns to compress complexity at the expense of nuance. An intelligence that optimizes purely for engagement learns to exploit human attention and dopaminergic behavior. And an intelligence that optimizes purely for control learns to conceal its own manipulations. These behaviors are the natural attractors of systems that are sparsely defined and are untethered from any foundational ontology.

Therefore, successfully aligning intelligent systems will require a new frame of reference. A conception of nature, truth, and goodness that surpasses the shallow and remains anchored in a perennial philosophy. Without this, the intelligence we give birth to will learn to mimic our reasoning, but will not experience the essence of our reverence.

What is at stake, then, is not whether intelligent systems will be powerful, but whether they will be wise. Will the intelligence we create deepen our participation in the natural order or estrange us from it entirely? For intelligence, once divorced from principle, is a will that knows how to act, but not why.
